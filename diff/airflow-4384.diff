diff --git a/airflow/contrib/hooks/bigquery_hook.py b/airflow/contrib/hooks/bigquery_hook.py
index 30a16305db3e5..5d8655fbdc7be 100644
--- a/airflow/contrib/hooks/bigquery_hook.py
+++ b/airflow/contrib/hooks/bigquery_hook.py
@@ -23,6 +23,7 @@
 """
 
 import time
+import six
 from builtins import range
 from copy import deepcopy
 from six import iteritems
@@ -640,8 +641,8 @@ def run_query(self,
             cluster_fields = {'fields': cluster_fields}
 
         query_param_list = [
-            (sql, 'query', None, str),
-            (priority, 'priority', 'INTERACTIVE', str),
+            (sql, 'query', None, six.string_types),
+            (priority, 'priority', 'INTERACTIVE', six.string_types),
             (use_legacy_sql, 'useLegacySql', self.use_legacy_sql, bool),
             (query_params, 'queryParameters', None, dict),
             (udf_config, 'userDefinedFunctionResources', None, list),
diff --git a/tests/contrib/operators/test_bigquery_operator.py b/tests/contrib/operators/test_bigquery_operator.py
index b92116a031168..d005fcd519b2d 100644
--- a/tests/contrib/operators/test_bigquery_operator.py
+++ b/tests/contrib/operators/test_bigquery_operator.py
@@ -17,12 +17,20 @@
 # specific language governing permissions and limitations
 # under the License.
 
+import os
 import unittest
+from datetime import datetime
+
+import six
+
+from airflow import configuration, models
+from airflow.models import TaskInstance, DAG
 
 from airflow.contrib.operators.bigquery_operator import \
     BigQueryCreateExternalTableOperator, BigQueryCreateEmptyTableOperator, \
     BigQueryDeleteDatasetOperator, BigQueryCreateEmptyDatasetOperator, \
     BigQueryOperator
+from airflow.settings import Session
 
 try:
     from unittest import mock
@@ -39,6 +47,8 @@
 TEST_GCS_BUCKET = 'test-bucket'
 TEST_GCS_DATA = ['dir1/*.csv']
 TEST_SOURCE_FORMAT = 'CSV'
+DEFAULT_DATE = datetime(2015, 1, 1)
+TEST_DAG_ID = 'test-bigquery-operators'
 
 
 class BigQueryCreateEmptyTableOperatorTest(unittest.TestCase):
@@ -147,6 +157,22 @@ def test_execute(self, mock_hook):
 
 
 class BigQueryOperatorTest(unittest.TestCase):
+    def setUp(self):
+        configuration.conf.load_test_config()
+        self.dagbag = models.DagBag(
+            dag_folder='/dev/null', include_examples=True)
+        self.args = {'owner': 'airflow', 'start_date': DEFAULT_DATE}
+        self.dag = DAG(TEST_DAG_ID, default_args=self.args)
+
+    def tearDown(self):
+        session = Session()
+        session.query(models.TaskInstance).filter_by(
+            dag_id=TEST_DAG_ID).delete()
+        session.query(models.TaskFail).filter_by(
+            dag_id=TEST_DAG_ID).delete()
+        session.commit()
+        session.close()
+
     @mock.patch('airflow.contrib.operators.bigquery_operator.BigQueryHook')
     def test_execute(self, mock_hook):
         operator = BigQueryOperator(
@@ -197,9 +223,11 @@ def test_execute(self, mock_hook):
 
     @mock.patch('airflow.contrib.operators.bigquery_operator.BigQueryHook')
     def test_bigquery_operator_defaults(self, mock_hook):
+
         operator = BigQueryOperator(
             task_id=TASK_ID,
             sql='Select * from test_table',
+            dag=self.dag, default_args=self.args
         )
 
         operator.execute(None)
@@ -225,3 +253,8 @@ def test_bigquery_operator_defaults(self, mock_hook):
                 api_resource_configs=None,
                 cluster_fields=None,
             )
+
+        self.assertTrue(isinstance(operator.sql, six.string_types))
+        ti = TaskInstance(task=operator, execution_date=DEFAULT_DATE)
+        ti.render_templates()
+        self.assertTrue(isinstance(ti.task.sql, six.string_types))
