[
    {
        "url": "https://api.github.com/repos/huggingface/transformers/issues/11956",
        "repository_url": "https://api.github.com/repos/huggingface/transformers",
        "labels_url": "https://api.github.com/repos/huggingface/transformers/issues/11956/labels{/name}",
        "comments_url": "https://api.github.com/repos/huggingface/transformers/issues/11956/comments",
        "events_url": "https://api.github.com/repos/huggingface/transformers/issues/11956/events",
        "html_url": "https://github.com/huggingface/transformers/pull/11956",
        "id": 907196016,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjU4MDc4OTc4",
        "number": 11956,
        "title": "Authorize args when instantiating an AutoModel",
        "user": {
            "login": "LysandreJik",
            "id": 30755778,
            "node_id": "MDQ6VXNlcjMwNzU1Nzc4",
            "avatar_url": "https://avatars.githubusercontent.com/u/30755778?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/LysandreJik",
            "html_url": "https://github.com/LysandreJik",
            "followers_url": "https://api.github.com/users/LysandreJik/followers",
            "following_url": "https://api.github.com/users/LysandreJik/following{/other_user}",
            "gists_url": "https://api.github.com/users/LysandreJik/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/LysandreJik/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/LysandreJik/subscriptions",
            "organizations_url": "https://api.github.com/users/LysandreJik/orgs",
            "repos_url": "https://api.github.com/users/LysandreJik/repos",
            "events_url": "https://api.github.com/users/LysandreJik/events{/privacy}",
            "received_events_url": "https://api.github.com/users/LysandreJik/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-05-31T07:49:26Z",
        "updated_at": "2021-06-03T01:51:07Z",
        "closed_at": "2021-06-01T13:27:54Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/huggingface/transformers/pulls/11956",
            "html_url": "https://github.com/huggingface/transformers/pull/11956",
            "diff_url": "https://github.com/huggingface/transformers/pull/11956.diff",
            "patch_url": "https://github.com/huggingface/transformers/pull/11956.patch"
        },
        "body": "The current `_BaseAutoModelClass` class initialization does not accept any argument, and therefore fails with an arcane error when instantiating it incorrectly, as shown in https://github.com/huggingface/transformers/issues/11953 by @g-karthik:\r\n\r\n```py\r\nfrom transformers import AutoConfig, AutoModelForCausalLM\r\n\r\nconfig = AutoConfig.from_pretrained(\"gpt2\", return_dict=True, gradient_checkpointing=False)\r\nmodel = AutoModelForCausalLM(config)\r\n```\r\n```out\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nTypeError: __init__() takes 1 positional argument but 2 were given\r\n```\r\n\r\nThis PR adds possible arguments and keyword arguments so that the error is always correctly raised:\r\n\r\n```out\r\nTraceback (most recent call last):\r\n  File \"<input>\", line 1, in <module>\r\n  File \"/home/xxx/transformers/src/transformers/models/auto/auto_factory.py\", line 361, in __init__\r\n    raise EnvironmentError(\r\nOSError: AutoModel is designed to be instantiated using the `AutoModel.from_pretrained(pretrained_model_name_or_path)` or `AutoModel.from_config(config)` methods.\r\n```\r\n\r\nTaking this opportunity to re-open the question asked by @g-karthik of whether the `AutoModel`s should have the ability to be instantiated using configuration objects via the `__init__`, similarly to other `PreTrainedModel`s.\r\n\r\n@patrickvonplaten @sgugger ",
        "performed_via_github_app": null,
        "score": 1.0
    },
    {
        "url": "https://api.github.com/repos/huggingface/transformers/issues/10672",
        "repository_url": "https://api.github.com/repos/huggingface/transformers",
        "labels_url": "https://api.github.com/repos/huggingface/transformers/issues/10672/labels{/name}",
        "comments_url": "https://api.github.com/repos/huggingface/transformers/issues/10672/comments",
        "events_url": "https://api.github.com/repos/huggingface/transformers/issues/10672/events",
        "html_url": "https://github.com/huggingface/transformers/pull/10672",
        "id": 829429241,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NTkxMDk2NTUw",
        "number": 10672,
        "title": "fix typing error for HfArgumentParser for Optional[bool]",
        "user": {
            "login": "bfineran",
            "id": 11316925,
            "node_id": "MDQ6VXNlcjExMzE2OTI1",
            "avatar_url": "https://avatars.githubusercontent.com/u/11316925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/bfineran",
            "html_url": "https://github.com/bfineran",
            "followers_url": "https://api.github.com/users/bfineran/followers",
            "following_url": "https://api.github.com/users/bfineran/following{/other_user}",
            "gists_url": "https://api.github.com/users/bfineran/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/bfineran/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/bfineran/subscriptions",
            "organizations_url": "https://api.github.com/users/bfineran/orgs",
            "repos_url": "https://api.github.com/users/bfineran/repos",
            "events_url": "https://api.github.com/users/bfineran/events{/privacy}",
            "received_events_url": "https://api.github.com/users/bfineran/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2021-03-11T18:48:31Z",
        "updated_at": "2021-03-11T22:42:54Z",
        "closed_at": "2021-03-11T22:42:54Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/huggingface/transformers/pulls/10672",
            "html_url": "https://github.com/huggingface/transformers/pull/10672",
            "diff_url": "https://github.com/huggingface/transformers/pull/10672.diff",
            "patch_url": "https://github.com/huggingface/transformers/pull/10672.patch"
        },
        "body": "`TrainingArguments` uses the `Optional[bool]` type for [a couple arguments](https://github.com/huggingface/transformers/blob/master/src/transformers/training_args.py#L443).  I ran into the following error when using transformers v4.3.3 with python 3.8:\r\n\r\n`\"TrainingArguments\" TypeError: issubclass() arg 1 must be a class`",
        "performed_via_github_app": null,
        "score": 1.0
    },
    {
        "url": "https://api.github.com/repos/huggingface/transformers/issues/11168",
        "repository_url": "https://api.github.com/repos/huggingface/transformers",
        "labels_url": "https://api.github.com/repos/huggingface/transformers/issues/11168/labels{/name}",
        "comments_url": "https://api.github.com/repos/huggingface/transformers/issues/11168/comments",
        "events_url": "https://api.github.com/repos/huggingface/transformers/issues/11168/events",
        "html_url": "https://github.com/huggingface/transformers/pull/11168",
        "id": 854692881,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NjEyNTk2OTA4",
        "number": 11168,
        "title": "[examples run_clm] fix _LazyModule hasher error",
        "user": {
            "login": "stas00",
            "id": 10676103,
            "node_id": "MDQ6VXNlcjEwNjc2MTAz",
            "avatar_url": "https://avatars.githubusercontent.com/u/10676103?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stas00",
            "html_url": "https://github.com/stas00",
            "followers_url": "https://api.github.com/users/stas00/followers",
            "following_url": "https://api.github.com/users/stas00/following{/other_user}",
            "gists_url": "https://api.github.com/users/stas00/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stas00/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stas00/subscriptions",
            "organizations_url": "https://api.github.com/users/stas00/orgs",
            "repos_url": "https://api.github.com/users/stas00/repos",
            "events_url": "https://api.github.com/users/stas00/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stas00/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2021-04-09T16:53:33Z",
        "updated_at": "2021-04-09T18:39:15Z",
        "closed_at": "2021-04-09T18:39:12Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/huggingface/transformers/pulls/11168",
            "html_url": "https://github.com/huggingface/transformers/pull/11168",
            "diff_url": "https://github.com/huggingface/transformers/pull/11168.diff",
            "patch_url": "https://github.com/huggingface/transformers/pull/11168.patch"
        },
        "body": "This PR fixes a problem I introduced in https://github.com/huggingface/transformers/pull/11145 and reported in https://github.com/huggingface/transformers/issues/11166 \r\n\r\n`datasets.fingerprint.Hasher` fails to run \r\n\r\n```\r\nhasher = Hasher()\r\nhasher.update(tokenize_function)\r\n```\r\ngetting:\r\n```\r\nTypeError: cannot pickle '_LazyModule' object\r\n```\r\n\r\nBecause the logger object contains a lazy import.\r\n\r\nThe error was subtle as the exception was caught and not propagated but instead a warning was logged, which I didn't notice in the first place. Warnings aren't a great way to communicate problems. So we were getting now:\r\n\r\n> [WARNING|tokenization_utils_base.py:3144] 2021-04-09 09:46:31,368 >> Token indices sequence length is longer than the specified maximum sequence length for this model (1462828 > 1024). Running this sequence through the model will result in indexing errors\r\n> [WARNING|run_clm.py:326] 2021-04-09 09:46:31,368 >> ^^^^^^^^^^^^^^^^ Please ignore the warning above - this long input will be chunked into smaller bits before being passed to the model.\r\n> 04/09/2021 09:46:31 - WARNING - datasets.fingerprint -   Parameter 'function'=<function main.<locals>.tokenize_function at 0x7f434d90da60> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\r\n\r\nSo I fixed this by moving the logger object fetching to outside of the function to be hashed and then it all works.\r\n\r\nFixes: https://github.com/huggingface/transformers/issues/11166 \r\n\r\n@sgugger \r\n",
        "performed_via_github_app": null,
        "score": 1.0
    },
    {
        "url": "https://api.github.com/repos/huggingface/transformers/issues/10662",
        "repository_url": "https://api.github.com/repos/huggingface/transformers",
        "labels_url": "https://api.github.com/repos/huggingface/transformers/issues/10662/labels{/name}",
        "comments_url": "https://api.github.com/repos/huggingface/transformers/issues/10662/comments",
        "events_url": "https://api.github.com/repos/huggingface/transformers/issues/10662/events",
        "html_url": "https://github.com/huggingface/transformers/pull/10662",
        "id": 829302257,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NTkwOTg4Njg4",
        "number": 10662,
        "title": "Specify minimum version for sacrebleu",
        "user": {
            "login": "LysandreJik",
            "id": 30755778,
            "node_id": "MDQ6VXNlcjMwNzU1Nzc4",
            "avatar_url": "https://avatars.githubusercontent.com/u/30755778?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/LysandreJik",
            "html_url": "https://github.com/LysandreJik",
            "followers_url": "https://api.github.com/users/LysandreJik/followers",
            "following_url": "https://api.github.com/users/LysandreJik/following{/other_user}",
            "gists_url": "https://api.github.com/users/LysandreJik/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/LysandreJik/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/LysandreJik/subscriptions",
            "organizations_url": "https://api.github.com/users/LysandreJik/orgs",
            "repos_url": "https://api.github.com/users/LysandreJik/repos",
            "events_url": "https://api.github.com/users/LysandreJik/events{/privacy}",
            "received_events_url": "https://api.github.com/users/LysandreJik/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2021-03-11T16:16:00Z",
        "updated_at": "2021-03-11T20:48:16Z",
        "closed_at": "2021-03-11T18:45:07Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/huggingface/transformers/pulls/10662",
            "html_url": "https://github.com/huggingface/transformers/pull/10662",
            "diff_url": "https://github.com/huggingface/transformers/pull/10662.diff",
            "patch_url": "https://github.com/huggingface/transformers/pull/10662.patch"
        },
        "body": "The `_tests_requirements.txt` require an install of sacrebleu without any version specified. However, some `sacrebleu` versions don't have the same API. I've had problems with version `1.2.10`, and @lhoestq confirmed the issue is not present in `1.4.12`.\r\n\r\nThe error was the following:\r\n\r\n```\r\n    def _compute(\r\n        self,\r\n        predictions,\r\n        references,\r\n        smooth_method=\"exp\",\r\n        smooth_value=None,\r\n        force=False,\r\n        lowercase=False,\r\n        tokenize=scb.DEFAULT_TOKENIZER,\r\n        use_effective_order=False,\r\n    ):\r\n        references_per_prediction = len(references[0])\r\n        if any(len(refs) != references_per_prediction for refs in references):\r\n            raise ValueError(\"Sacrebleu requires the same number of references for each prediction\")\r\n        transformed_references = [[refs[i] for refs in references] for i in range(references_per_prediction)]\r\n>       output = scb.corpus_bleu(\r\n            sys_stream=predictions,\r\n            ref_streams=transformed_references,\r\n            smooth_method=smooth_method,\r\n            smooth_value=smooth_value,\r\n            force=force,\r\n            lowercase=lowercase,\r\n            tokenize=tokenize,\r\n            use_effective_order=use_effective_order,\r\n        )\r\nE       TypeError: corpus_bleu() got an unexpected keyword argument 'smooth_method'\r\n/mnt/cache/modules/datasets_modules/metrics/sacrebleu/b390045b3d1dd4abf6a95c4a2a11ee3bcc2b7620b076204d0ddc353fa649fd86/sacrebleu.py:114: TypeError\r\n```\r\n\r\nFull stack trace:\r\n\r\n```\r\nE             File \"/__w/transformers/transformers/src/transformers/trainer_seq2seq.py\", line 74, in evaluate\r\nE               return super().evaluate(eval_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)\r\nE             File \"/__w/transformers/transformers/src/transformers/trainer.py\", line 1650, in evaluate\r\nE               output = self.prediction_loop(\r\nE             File \"/__w/transformers/transformers/src/transformers/trainer.py\", line 1823, in prediction_loop\r\nE               metrics = self.compute_metrics(EvalPrediction(predictions=preds, label_ids=label_ids))\r\nE             File \"/__w/transformers/transformers/examples/seq2seq/run_seq2seq.py\", line 563, in compute_metrics\r\nE               result = metric.compute(predictions=decoded_preds, references=decoded_labels)\r\nE             File \"/opt/conda/lib/python3.8/site-packages/datasets/metric.py\", line 403, in compute\r\nE               output = self._compute(predictions=predictions, references=references, **kwargs)\r\nE             File \"/mnt/cache/modules/datasets_modules/metrics/sacrebleu/b390045b3d1dd4abf6a95c4a2a11ee3bcc2b7620b076204d0ddc353fa649fd86/sacrebleu.py\", line 114, in _compute\r\nE               output = scb.corpus_bleu(\r\n```\r\n\r\nI'm unsure about the minimum version required here, I just know that 1.2.10 doesn't work. Please advise if you think a better minimum version would be better.",
        "performed_via_github_app": null,
        "score": 1.0
    },
    {
        "url": "https://api.github.com/repos/huggingface/transformers/issues/9273",
        "repository_url": "https://api.github.com/repos/huggingface/transformers",
        "labels_url": "https://api.github.com/repos/huggingface/transformers/issues/9273/labels{/name}",
        "comments_url": "https://api.github.com/repos/huggingface/transformers/issues/9273/comments",
        "events_url": "https://api.github.com/repos/huggingface/transformers/issues/9273/events",
        "html_url": "https://github.com/huggingface/transformers/pull/9273",
        "id": 773632876,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NTQ0Njg0ODE4",
        "number": 9273,
        "title": "Fix param error",
        "user": {
            "login": "xu-song",
            "id": 13825126,
            "node_id": "MDQ6VXNlcjEzODI1MTI2",
            "avatar_url": "https://avatars.githubusercontent.com/u/13825126?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xu-song",
            "html_url": "https://github.com/xu-song",
            "followers_url": "https://api.github.com/users/xu-song/followers",
            "following_url": "https://api.github.com/users/xu-song/following{/other_user}",
            "gists_url": "https://api.github.com/users/xu-song/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xu-song/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xu-song/subscriptions",
            "organizations_url": "https://api.github.com/users/xu-song/orgs",
            "repos_url": "https://api.github.com/users/xu-song/repos",
            "events_url": "https://api.github.com/users/xu-song/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xu-song/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2020-12-23T09:56:57Z",
        "updated_at": "2020-12-23T10:34:58Z",
        "closed_at": "2020-12-23T10:34:58Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/huggingface/transformers/pulls/9273",
            "html_url": "https://github.com/huggingface/transformers/pull/9273",
            "diff_url": "https://github.com/huggingface/transformers/pull/9273.diff",
            "patch_url": "https://github.com/huggingface/transformers/pull/9273.patch"
        },
        "body": "\r\n\r\n# What does this PR do?\r\n\r\n\r\nFixes error\r\n```\r\nTypeError: forward() got an unexpected keyword argument 'token_type_ids'\r\n```\r\n\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/master/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/master/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/master/docs#writing-source-documentation).\r\n- [x] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors which may be interested in your PR.\r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\n albert, bert, XLM: @LysandreJik\r\n GPT2: @LysandreJik, @patrickvonplaten\r\n tokenizers: @mfuntowicz\r\n Trainer: @sgugger\r\n Benchmarks: @patrickvonplaten\r\n Model Cards: @julien-c\r\n examples/distillation: @VictorSanh\r\n nlp datasets: [different repo](https://github.com/huggingface/nlp)\r\n rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n Text Generation: @patrickvonplaten, @TevenLeScao\r\n Blenderbot, Bart, Marian, Pegasus: @patrickvonplaten\r\n T5: @patrickvonplaten\r\n Rag: @patrickvonplaten, @lhoestq\r\n EncoderDecoder: @patrickvonplaten\r\n Longformer, Reformer: @patrickvonplaten\r\n TransfoXL, XLNet: @TevenLeScao, @patrickvonplaten\r\n examples/seq2seq: @patil-suraj\r\n examples/bert-loses-patience: @JetRunner\r\n tensorflow: @jplu\r\n examples/token-classification: @stefan-it\r\n documentation: @sgugger\r\n FSMT: @stas00\r\n -->\r\n",
        "performed_via_github_app": null,
        "score": 1.0
    },
    {
        "url": "https://api.github.com/repos/huggingface/transformers/issues/8929",
        "repository_url": "https://api.github.com/repos/huggingface/transformers",
        "labels_url": "https://api.github.com/repos/huggingface/transformers/issues/8929/labels{/name}",
        "comments_url": "https://api.github.com/repos/huggingface/transformers/issues/8929/comments",
        "events_url": "https://api.github.com/repos/huggingface/transformers/issues/8929/events",
        "html_url": "https://github.com/huggingface/transformers/pull/8929",
        "id": 757404939,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NTMyNzg3NjM2",
        "number": 8929,
        "title": "Don't pass in token_type_ids to BART for GLUE",
        "user": {
            "login": "ethanjperez",
            "id": 6402205,
            "node_id": "MDQ6VXNlcjY0MDIyMDU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6402205?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ethanjperez",
            "html_url": "https://github.com/ethanjperez",
            "followers_url": "https://api.github.com/users/ethanjperez/followers",
            "following_url": "https://api.github.com/users/ethanjperez/following{/other_user}",
            "gists_url": "https://api.github.com/users/ethanjperez/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ethanjperez/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ethanjperez/subscriptions",
            "organizations_url": "https://api.github.com/users/ethanjperez/orgs",
            "repos_url": "https://api.github.com/users/ethanjperez/repos",
            "events_url": "https://api.github.com/users/ethanjperez/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ethanjperez/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2020-12-04T21:05:21Z",
        "updated_at": "2020-12-05T14:52:17Z",
        "closed_at": "2020-12-05T14:52:17Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/huggingface/transformers/pulls/8929",
            "html_url": "https://github.com/huggingface/transformers/pull/8929",
            "diff_url": "https://github.com/huggingface/transformers/pull/8929.diff",
            "patch_url": "https://github.com/huggingface/transformers/pull/8929.patch"
        },
        "body": "# What does this PR do?\r\n\r\nWithout this fix, training a `BARTForSequenceClassification` model with `run_pl_glue.py` gives `TypeError: forward() got an unexpected keyword argument 'token_type_ids'`, because BART does not have token_type_ids. I've solved this issue in the same way as it's solved for the \"distilbert\" model, and I can train BART models on SNLI without errors now.\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/master/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/master/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/master/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\n@patrickvonplaten\r\n\r\n",
        "performed_via_github_app": null,
        "score": 1.0
    },
    {
        "url": "https://api.github.com/repos/huggingface/transformers/issues/9186",
        "repository_url": "https://api.github.com/repos/huggingface/transformers",
        "labels_url": "https://api.github.com/repos/huggingface/transformers/issues/9186/labels{/name}",
        "comments_url": "https://api.github.com/repos/huggingface/transformers/issues/9186/comments",
        "events_url": "https://api.github.com/repos/huggingface/transformers/issues/9186/events",
        "html_url": "https://github.com/huggingface/transformers/pull/9186",
        "id": 770739076,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NTQyNDI4MjM2",
        "number": 9186,
        "title": "fixed not JSON serializable error in run_qa.py with fp16",
        "user": {
            "login": "WissamAntoun",
            "id": 44616226,
            "node_id": "MDQ6VXNlcjQ0NjE2MjI2",
            "avatar_url": "https://avatars.githubusercontent.com/u/44616226?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/WissamAntoun",
            "html_url": "https://github.com/WissamAntoun",
            "followers_url": "https://api.github.com/users/WissamAntoun/followers",
            "following_url": "https://api.github.com/users/WissamAntoun/following{/other_user}",
            "gists_url": "https://api.github.com/users/WissamAntoun/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/WissamAntoun/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/WissamAntoun/subscriptions",
            "organizations_url": "https://api.github.com/users/WissamAntoun/orgs",
            "repos_url": "https://api.github.com/users/WissamAntoun/repos",
            "events_url": "https://api.github.com/users/WissamAntoun/events{/privacy}",
            "received_events_url": "https://api.github.com/users/WissamAntoun/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2020-12-18T09:40:50Z",
        "updated_at": "2020-12-18T12:53:24Z",
        "closed_at": "2020-12-18T12:53:24Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/huggingface/transformers/pulls/9186",
            "html_url": "https://github.com/huggingface/transformers/pull/9186",
            "diff_url": "https://github.com/huggingface/transformers/pull/9186.diff",
            "patch_url": "https://github.com/huggingface/transformers/pull/9186.patch"
        },
        "body": "# What does this PR do?\r\n\r\nFixed an issue where running the run_qa.py script in a Squad-like dataset with fp16 enabled, would lead to a JSON serialization error:\r\n```\r\nTypeError: Object of type 'float16' is not JSON serializable\r\n```\r\nThe bug is caused by not converting `np.float16` to `float` on line 209 and 397 in the utils_qa.py file.\r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/master/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section? --> yes \r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case. --> no\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/master/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/master/docs#writing-source-documentation). --> No need for it\r\n- [x] Did you write any new necessary tests? No\r\n\r\n\r\n## Who can review?\r\n @sgugger \r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors which may be interested in your PR.\r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\n albert, bert, XLM: @LysandreJik\r\n GPT2: @LysandreJik, @patrickvonplaten\r\n tokenizers: @mfuntowicz\r\n Trainer: @sgugger\r\n Benchmarks: @patrickvonplaten\r\n Model Cards: @julien-c\r\n examples/distillation: @VictorSanh\r\n nlp datasets: [different repo](https://github.com/huggingface/nlp)\r\n rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n Text Generation: @patrickvonplaten, @TevenLeScao\r\n Blenderbot, Bart, Marian, Pegasus: @patrickvonplaten\r\n T5: @patrickvonplaten\r\n Rag: @patrickvonplaten, @lhoestq\r\n EncoderDecoder: @patrickvonplaten\r\n Longformer, Reformer: @patrickvonplaten\r\n TransfoXL, XLNet: @TevenLeScao, @patrickvonplaten\r\n examples/seq2seq: @patil-suraj\r\n examples/bert-loses-patience: @JetRunner\r\n tensorflow: @jplu\r\n examples/token-classification: @stefan-it\r\n documentation: @sgugger\r\n FSMT: @stas00\r\n -->\r\n",
        "performed_via_github_app": null,
        "score": 1.0
    },
    {
        "url": "https://api.github.com/repos/huggingface/transformers/issues/8052",
        "repository_url": "https://api.github.com/repos/huggingface/transformers",
        "labels_url": "https://api.github.com/repos/huggingface/transformers/issues/8052/labels{/name}",
        "comments_url": "https://api.github.com/repos/huggingface/transformers/issues/8052/comments",
        "events_url": "https://api.github.com/repos/huggingface/transformers/issues/8052/events",
        "html_url": "https://github.com/huggingface/transformers/pull/8052",
        "id": 729629218,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NTEwMDgyODcw",
        "number": 8052,
        "title": "Fix a bug for `CallbackHandler.callback_list`",
        "user": {
            "login": "harupy",
            "id": 17039389,
            "node_id": "MDQ6VXNlcjE3MDM5Mzg5",
            "avatar_url": "https://avatars.githubusercontent.com/u/17039389?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/harupy",
            "html_url": "https://github.com/harupy",
            "followers_url": "https://api.github.com/users/harupy/followers",
            "following_url": "https://api.github.com/users/harupy/following{/other_user}",
            "gists_url": "https://api.github.com/users/harupy/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/harupy/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/harupy/subscriptions",
            "organizations_url": "https://api.github.com/users/harupy/orgs",
            "repos_url": "https://api.github.com/users/harupy/repos",
            "events_url": "https://api.github.com/users/harupy/events{/privacy}",
            "received_events_url": "https://api.github.com/users/harupy/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2020-10-26T14:47:10Z",
        "updated_at": "2020-10-27T14:47:03Z",
        "closed_at": "2020-10-27T14:37:05Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/huggingface/transformers/pulls/8052",
            "html_url": "https://github.com/huggingface/transformers/pull/8052",
            "diff_url": "https://github.com/huggingface/transformers/pull/8052.diff",
            "patch_url": "https://github.com/huggingface/transformers/pull/8052.patch"
        },
        "body": "# What does this PR do?\r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\nFix a bug where `CallbackHandler.callback_list` fails when given callbacks are duplicated:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-40-9605b122f4d1> in <module>()\r\n      2 from transformers.trainer import DEFAULT_CALLBACKS\r\n      3 \r\n----> 4 CallbackHandler(DEFAULT_CALLBACKS + [MLflowCallback], \"model\", \"optimizer\", \"lr_scheduler\")\r\n\r\n2 frames\r\n/usr/local/lib/python3.6/dist-packages/transformers/trainer_callback.py in __init__(self, callbacks, model, optimizer, lr_scheduler)\r\n    277         self.callbacks = []\r\n    278         for cb in callbacks:\r\n--> 279             self.add_callback(cb)\r\n    280         self.model = model\r\n    281         self.optimizer = optimizer\r\n\r\n/usr/local/lib/python3.6/dist-packages/transformers/trainer_callback.py in add_callback(self, callback)\r\n    299                 f\"You are adding a {cb_class} to the callbacks of this Trainer, but there is already one. The current\"\r\n    300                 + \"list of callbacks is\\n:\"\r\n--> 301                 + self.callback_list\r\n    302             )\r\n    303         self.callbacks.append(cb)\r\n\r\n/usr/local/lib/python3.6/dist-packages/transformers/trainer_callback.py in callback_list(self)\r\n    326     @property\r\n    327     def callback_list(self):\r\n--> 328         return \"\\n\".join(self.callbacks)\r\n    329 \r\n    330     def on_init_end(self, args: TrainingArguments, state: TrainerState, control: TrainerControl):\r\n\r\nTypeError: sequence item 0: expected str instance, DefaultFlowCallback found\r\n```\r\n\r\nCode to reproduce the bug:\r\n\r\n```python\r\nfrom transformers.trainer_callback import CallbackHandler\r\nfrom transformers.trainer import DEFAULT_CALLBACKS\r\n\r\nCallbackHandler(DEFAULT_CALLBACKS + [MLflowCallback], \"model\", \"optimizer\", \"lr_scheduler\")\r\n```\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/master/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to the it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/master/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/master/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\n@sgugger\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors which may be interested in your PR.\r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\n albert, bert, XLM: @LysandreJik\r\n GPT2: @LysandreJik, @patrickvonplaten\r\n tokenizers: @mfuntowicz\r\n Trainer: @sgugger\r\n Benchmarks: @patrickvonplaten\r\n Model Cards: @julien-c\r\n Translation: @sshleifer\r\n Summarization: @sshleifer\r\n examples/distillation: @VictorSanh\r\n nlp datasets: [different repo](https://github.com/huggingface/nlp)\r\n rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n Text Generation: @patrickvonplaten, @TevenLeScao\r\n Blenderbot, Bart, Marian, Pegasus: @sshleifer\r\n T5: @patrickvonplaten\r\n Rag: @patrickvonplaten, @lhoestq\r\n EncoderDecoder: @patrickvonplaten\r\n Longformer, Reformer: @patrickvonplaten\r\n TransfoXL, XLNet: @TevenLeScao, @patrickvonplaten\r\n examples/seq2seq: @sshleifer\r\n examples/bert-loses-patience: @JetRunner\r\n tensorflow: @jplu\r\n examples/token-classification: @stefan-it\r\n documentation: @sgugger\r\n -->\r\n",
        "performed_via_github_app": null,
        "score": 1.0
    },
    {
        "url": "https://api.github.com/repos/huggingface/transformers/issues/7843",
        "repository_url": "https://api.github.com/repos/huggingface/transformers",
        "labels_url": "https://api.github.com/repos/huggingface/transformers/issues/7843/labels{/name}",
        "comments_url": "https://api.github.com/repos/huggingface/transformers/issues/7843/comments",
        "events_url": "https://api.github.com/repos/huggingface/transformers/issues/7843/events",
        "html_url": "https://github.com/huggingface/transformers/pull/7843",
        "id": 722880286,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NTA0NTY0MjE1",
        "number": 7843,
        "title": "[seq2seq] get_git_info fails gracefully",
        "user": {
            "login": "stas00",
            "id": 10676103,
            "node_id": "MDQ6VXNlcjEwNjc2MTAz",
            "avatar_url": "https://avatars.githubusercontent.com/u/10676103?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stas00",
            "html_url": "https://github.com/stas00",
            "followers_url": "https://api.github.com/users/stas00/followers",
            "following_url": "https://api.github.com/users/stas00/following{/other_user}",
            "gists_url": "https://api.github.com/users/stas00/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stas00/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stas00/subscriptions",
            "organizations_url": "https://api.github.com/users/stas00/orgs",
            "repos_url": "https://api.github.com/users/stas00/repos",
            "events_url": "https://api.github.com/users/stas00/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stas00/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2020-10-16T04:13:52Z",
        "updated_at": "2020-10-16T04:23:35Z",
        "closed_at": "2020-10-16T04:22:44Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/huggingface/transformers/pulls/7843",
            "html_url": "https://github.com/huggingface/transformers/pull/7843",
            "diff_url": "https://github.com/huggingface/transformers/pull/7843.diff",
            "patch_url": "https://github.com/huggingface/transformers/pull/7843.patch"
        },
        "body": "It looks like gitpython is broken when one tries to use it from `git checkout hash`, see: https://github.com/gitpython-developers/GitPython/issues/633\r\n\r\nWhile debugging/bisecting we need to be able to step through different commits and for the code to still work. \r\n\r\nCurrently if I do:\r\n```\r\ngit checkout fb94b8f1e16eb\r\n```\r\nand run an examples test, like `examples/seq2seq/test_seq2seq_examples_multi_gpu.py` (soon to be merged) it fails with:\r\n```\r\nERR:   File \"./examples/seq2seq/distillation.py\", line 504, in <module>\r\nERR:     distill_main(args)\r\nERR:   File \"./examples/seq2seq/distillation.py\", line 494, in distill_main\r\nERR:     model = create_module(args)\r\nERR:   File \"./examples/seq2seq/distillation.py\", line 411, in create_module\r\nERR:     model = module_cls(args)\r\nERR:   File \"/mnt/nvme1/code/huggingface/transformers-multigpu/examples/seq2seq/finetune.py\", line 58, in __init__\r\nERR:     save_git_info(self.hparams.output_dir)\r\nERR:   File \"/mnt/nvme1/code/huggingface/transformers-multigpu/examples/seq2seq/utils.py\", line 355, in save_git_info\r\nERR:     repo_infos = get_git_info()\r\nERR:   File \"/mnt/nvme1/code/huggingface/transformers-multigpu/examples/seq2seq/utils.py\", line 374, in get_git_info\r\nERR:     \"repo_branch\": str(repo.active_branch),\r\nERR:   File \"/home/stas/anaconda3/envs/main-38/lib/python3.8/site-packages/git/repo/base.py\", line 705, in active_branch\r\nERR:     return self.head.reference\r\nERR:   File \"/home/stas/anaconda3/envs/main-38/lib/python3.8/site-packages/git/refs/symbolic.py\", line 272, in _get_reference\r\nERR:     raise TypeError(\"%s is a detached symbolic reference as it points to %r\" % (self, sha))\r\nERR: TypeError: HEAD is a detached symbolic reference as it points to 'fb94b8f1e16eb21d166174f52e3e49e669ef0ac4'\r\n```\r\n\r\nThe odd leading `ERR` string is just a replay of stderr from the sub-process - please ignore this nuance.\r\n\r\nThis PR provides a workaround.\r\n\r\n@sshleifer\r\n",
        "performed_via_github_app": null,
        "score": 1.0
    },
    {
        "url": "https://api.github.com/repos/huggingface/transformers/issues/6634",
        "repository_url": "https://api.github.com/repos/huggingface/transformers",
        "labels_url": "https://api.github.com/repos/huggingface/transformers/issues/6634/labels{/name}",
        "comments_url": "https://api.github.com/repos/huggingface/transformers/issues/6634/comments",
        "events_url": "https://api.github.com/repos/huggingface/transformers/issues/6634/events",
        "html_url": "https://github.com/huggingface/transformers/pull/6634",
        "id": 683400181,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NDcxNDk4ODM5",
        "number": 6634,
        "title": "Fix error class instantiation",
        "user": {
            "login": "tamuhey",
            "id": 24998666,
            "node_id": "MDQ6VXNlcjI0OTk4NjY2",
            "avatar_url": "https://avatars.githubusercontent.com/u/24998666?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tamuhey",
            "html_url": "https://github.com/tamuhey",
            "followers_url": "https://api.github.com/users/tamuhey/followers",
            "following_url": "https://api.github.com/users/tamuhey/following{/other_user}",
            "gists_url": "https://api.github.com/users/tamuhey/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tamuhey/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tamuhey/subscriptions",
            "organizations_url": "https://api.github.com/users/tamuhey/orgs",
            "repos_url": "https://api.github.com/users/tamuhey/repos",
            "events_url": "https://api.github.com/users/tamuhey/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tamuhey/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2020-08-21T08:41:05Z",
        "updated_at": "2020-09-02T11:36:33Z",
        "closed_at": "2020-09-02T11:36:33Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/huggingface/transformers/pulls/6634",
            "html_url": "https://github.com/huggingface/transformers/pull/6634",
            "diff_url": "https://github.com/huggingface/transformers/pull/6634.diff",
            "patch_url": "https://github.com/huggingface/transformers/pull/6634.patch"
        },
        "body": "The lines I fixed are bugs, causing `TypeError: 'ModuleNotFoundError' object is not callable`\t\t",
        "performed_via_github_app": null,
        "score": 1.0
    },
    {
        "url": "https://api.github.com/repos/huggingface/transformers/issues/9355",
        "repository_url": "https://api.github.com/repos/huggingface/transformers",
        "labels_url": "https://api.github.com/repos/huggingface/transformers/issues/9355/labels{/name}",
        "comments_url": "https://api.github.com/repos/huggingface/transformers/issues/9355/comments",
        "events_url": "https://api.github.com/repos/huggingface/transformers/issues/9355/events",
        "html_url": "https://github.com/huggingface/transformers/pull/9355",
        "id": 776271952,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NTQ2Nzk3NTEx",
        "number": 9355,
        "title": "Fix typos in README and bugs in RAG example code for end-to-end evaluation and finetuning",
        "user": {
            "login": "yoshitomo-matsubara",
            "id": 11156001,
            "node_id": "MDQ6VXNlcjExMTU2MDAx",
            "avatar_url": "https://avatars.githubusercontent.com/u/11156001?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yoshitomo-matsubara",
            "html_url": "https://github.com/yoshitomo-matsubara",
            "followers_url": "https://api.github.com/users/yoshitomo-matsubara/followers",
            "following_url": "https://api.github.com/users/yoshitomo-matsubara/following{/other_user}",
            "gists_url": "https://api.github.com/users/yoshitomo-matsubara/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yoshitomo-matsubara/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yoshitomo-matsubara/subscriptions",
            "organizations_url": "https://api.github.com/users/yoshitomo-matsubara/orgs",
            "repos_url": "https://api.github.com/users/yoshitomo-matsubara/repos",
            "events_url": "https://api.github.com/users/yoshitomo-matsubara/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yoshitomo-matsubara/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2020-12-30T05:25:13Z",
        "updated_at": "2021-01-03T17:25:04Z",
        "closed_at": "2021-01-03T15:00:30Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/huggingface/transformers/pulls/9355",
            "html_url": "https://github.com/huggingface/transformers/pull/9355",
            "diff_url": "https://github.com/huggingface/transformers/pull/9355.diff",
            "patch_url": "https://github.com/huggingface/transformers/pull/9355.patch"
        },
        "body": "# What does this PR do?\r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\nThis PR fixes bugs in RAG example code for [end-to-end evaluation](https://github.com/huggingface/transformers/tree/master/examples/research_projects/rag#end-to-end-evaluation) and [finetuning](https://github.com/huggingface/transformers/tree/master/examples/research_projects/rag#finetuning).\r\n\r\n## 1. Follow the file paths of reorganized examples\r\nAlso, the file paths for example code in README are updated (`example/rag/` -> `example/research_projects/rag/`)\r\n\r\n## 2. End-to-end evaluation\r\n```\r\npython examples/research_projects/rag/eval_rag.py \\\r\n    --model_name_or_path facebook/rag-sequence-nq \\\r\n    --model_type rag_sequence \\\r\n    --evaluation_set path/to/dev.source \\\r\n    --gold_data_path path/to/dev.gold_data \\ # parsed `biencoder-nq-dev.json` following `qa` format\r\n    --predictions_path path/to/e2e_preds.txt \\\r\n    --eval_mode e2e \\\r\n    --gold_data_mode qa \\\r\n    --n_docs 5 \\ # You can experiment with retrieving different number of documents at evaluation time\r\n    --print_predictions \\\r\n    --recalculate\r\n```\r\n\r\nWith the above command, I encountered a few errors:\r\n1. an unexpected keyword argument 'clean_up_tokenization'\r\n```\r\nSome weights of RagSequenceForGeneration were not initialized from the model checkpoint at facebook/rag-sequence-nq and are newly initialized: ['rag.generator.lm_head.weight']\r\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\ninitializing retrieval\r\nLoading index from https://storage.googleapis.com/huggingface-nlp/datasets/wiki_dpr/\r\nloading file https://storage.googleapis.com/huggingface-nlp/datasets/wiki_dpr/hf_bert_base.hnswSQ8_correct_phi_128.c_index.index.dpr from cache at /home/ubuntu/.cache/huggingface/transformers/a481b3aaed56325cb8901610e03e76f93b47f4284a1392d85e2ba5ce5d40d174.a382b038f1ea97c4fbad3098cd4a881a7cd4c5f73902c093e0c560511655cc0b\r\nloading file https://storage.googleapis.com/huggingface-nlp/datasets/wiki_dpr/hf_bert_base.hnswSQ8_correct_phi_128.c_index.index_meta.dpr from cache at /home/ubuntu/.cache/huggingface/transformers/bb9560964463bc761c682818cbdb4e1662e91d25a9407afb102970f00445678c.f8cbe3240b82ffaad54506b5c13c63d26ff873d5cfabbc30eef9ad668264bab4\r\n7it [00:00, 54.03it/s]\r\nTraceback (most recent call last):\r\n  File \"examples/research_projects/rag/eval_rag.py\", line 314, in <module>\r\n    main(args)\r\n  File \"examples/research_projects/rag/eval_rag.py\", line 300, in main\r\n    answers = evaluate_batch_fn(args, model, questions)\r\n  File \"examples/research_projects/rag/eval_rag.py\", line 134, in evaluate_batch_e2e\r\n    print_docs=args.print_docs,\r\n  File \"/home/ubuntu/.local/share/virtualenvs/transformers-zPEj0XTF/lib/python3.7/site-packages/torch/autograd/grad_mode.py\", line 26, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File \"/home/ubuntu/workspace/transformers/src/transformers/models/rag/modeling_rag.py\", line 923, in generate\r\n    **model_kwargs,\r\n  File \"/home/ubuntu/.local/share/virtualenvs/transformers-zPEj0XTF/lib/python3.7/site-packages/torch/autograd/grad_mode.py\", line 26, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File \"/home/ubuntu/workspace/transformers/src/transformers/generation_utils.py\", line 503, in generate\r\n    model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(input_ids, model_kwargs)\r\n  File \"/home/ubuntu/workspace/transformers/src/transformers/generation_utils.py\", line 86, in _prepare_encoder_decoder_kwargs_for_generation\r\n    model_kwargs[\"encoder_outputs\"]: ModelOutput = encoder(input_ids, return_dict=True, **encoder_kwargs)\r\n  File \"/home/ubuntu/.local/share/virtualenvs/transformers-zPEj0XTF/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\nTypeError: forward() got an unexpected keyword argument 'clean_up_tokenization'\r\n```\r\n\r\n2. another unexpected keyword argument 'print_docs'\r\n```\r\nSome weights of RagSequenceForGeneration were not initialized from the model checkpoint at facebook/rag-sequence-nq and are newly initialized: ['rag.generator.lm_head.weight']\r\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\ninitializing retrieval\r\nLoading index from https://storage.googleapis.com/huggingface-nlp/datasets/wiki_dpr/\r\nloading file https://storage.googleapis.com/huggingface-nlp/datasets/wiki_dpr/hf_bert_base.hnswSQ8_correct_phi_128.c_index.index.dpr from cache at /home/ubuntu/.cache/huggingface/transformers/a481b3aaed56325cb8901610e03e76f93b47f4284a1392d85e2ba5ce5d40d174.a382b038f1ea97c4fbad3098cd4a881a7cd4c5f73902c093e0c560511655cc0b\r\nloading file https://storage.googleapis.com/huggingface-nlp/datasets/wiki_dpr/hf_bert_base.hnswSQ8_correct_phi_128.c_index.index_meta.dpr from cache at /home/ubuntu/.cache/huggingface/transformers/bb9560964463bc761c682818cbdb4e1662e91d25a9407afb102970f00445678c.f8cbe3240b82ffaad54506b5c13c63d26ff873d5cfabbc30eef9ad668264bab4\r\n7it [00:00, 45.43it/s]\r\nTraceback (most recent call last):\r\n  File \"examples/research_projects/rag/eval_rag.py\", line 314, in <module>\r\n    main(args)\r\n  File \"examples/research_projects/rag/eval_rag.py\", line 300, in main\r\n    answers = evaluate_batch_fn(args, model, questions)\r\n  File \"examples/research_projects/rag/eval_rag.py\", line 134, in evaluate_batch_e2e\r\n    print_docs=args.print_docs,\r\n  File \"/home/ubuntu/.local/share/virtualenvs/transformers-zPEj0XTF/lib/python3.7/site-packages/torch/autograd/grad_mode.py\", line 26, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File \"/home/ubuntu/workspace/transformers/src/transformers/models/rag/modeling_rag.py\", line 923, in generate\r\n    **model_kwargs,\r\n  File \"/home/ubuntu/.local/share/virtualenvs/transformers-zPEj0XTF/lib/python3.7/site-packages/torch/autograd/grad_mode.py\", line 26, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File \"/home/ubuntu/workspace/transformers/src/transformers/generation_utils.py\", line 503, in generate\r\n    model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(input_ids, model_kwargs)\r\n  File \"/home/ubuntu/workspace/transformers/src/transformers/generation_utils.py\", line 86, in _prepare_encoder_decoder_kwargs_for_generation\r\n    model_kwargs[\"encoder_outputs\"]: ModelOutput = encoder(input_ids, return_dict=True, **encoder_kwargs)\r\n  File \"/home/ubuntu/.local/share/virtualenvs/transformers-zPEj0XTF/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\nTypeError: forward() got an unexpected keyword argument 'print_docs'\r\n```\r\n\r\n## 3. Finetuning\r\n```\r\npython examples/research_projects/rag/finetune_rag.py \\\r\n    --data_dir $DATA_DIR \\\r\n    --output_dir $OUTPUT_DIR \\\r\n    --model_name_or_path $MODEL_NAME_OR_PATH \\\r\n    --model_type rag_sequence \\\r\n    --fp16 \\\r\n    --gpus 8\r\n```\r\nWith the above command, I found two easy bugs to be fixed:\r\n1. [missing `return parser`](https://github.com/huggingface/transformers/blob/8217d4e37fce48490a68af7e8ce902af16318132/examples/research_projects/rag/finetune_rag.py#L498) returns None to `parser` and crashes [here](https://github.com/huggingface/transformers/blob/8217d4e37fce48490a68af7e8ce902af16318132/examples/research_projects/rag/finetune_rag.py#L528-L531)\r\n2. [duplicated argument with `num_retrieval_workers`](https://github.com/huggingface/transformers/blob/8217d4e37fce48490a68af7e8ce902af16318132/examples/research_projects/rag/finetune_rag.py#L490-L508) is also a blocker when using `finetune_rag.py`\r\n\r\n## Environments\r\n- Ubuntu 18.04 LTS\r\n- Python 3.7.7\r\n- transformers (I tried both 4.1.1 from pip and from repo https://github.com/huggingface/transformers/commit/912f6881d2b69f180522172a5283702bd8c41d9c)\r\n- torch: 1.7.1\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/master/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/master/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/master/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors which may be interested in your PR.\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\n albert, bert, XLM: @LysandreJik\r\n GPT2: @LysandreJik, @patrickvonplaten\r\n tokenizers: @mfuntowicz\r\n Trainer: @sgugger\r\n Benchmarks: @patrickvonplaten\r\n Model Cards: @julien-c\r\n examples/distillation: @VictorSanh\r\n nlp datasets: [different repo](https://github.com/huggingface/nlp)\r\n rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n Text Generation: @patrickvonplaten, @TevenLeScao\r\n Blenderbot, Bart, Marian, Pegasus: @patrickvonplaten\r\n T5: @patrickvonplaten\r\n Rag: @patrickvonplaten, @lhoestq\r\n EncoderDecoder: @patrickvonplaten\r\n Longformer, Reformer: @patrickvonplaten\r\n TransfoXL, XLNet: @TevenLeScao, @patrickvonplaten\r\n examples/seq2seq: @patil-suraj\r\n examples/bert-loses-patience: @JetRunner\r\n tensorflow: @jplu\r\n examples/token-classification: @stefan-it\r\n documentation: @sgugger\r\n FSMT: @stas00\r\n -->\r\n@patrickvonplaten @lhoestq\r\n",
        "performed_via_github_app": null,
        "score": 1.0
    },
    {
        "url": "https://api.github.com/repos/huggingface/transformers/issues/7880",
        "repository_url": "https://api.github.com/repos/huggingface/transformers",
        "labels_url": "https://api.github.com/repos/huggingface/transformers/issues/7880/labels{/name}",
        "comments_url": "https://api.github.com/repos/huggingface/transformers/issues/7880/comments",
        "events_url": "https://api.github.com/repos/huggingface/transformers/issues/7880/events",
        "html_url": "https://github.com/huggingface/transformers/pull/7880",
        "id": 723964030,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NTA1NDQwMzI1",
        "number": 7880,
        "title": "Fix bug in _sorted_checkpoints",
        "user": {
            "login": "shaie",
            "id": 3469932,
            "node_id": "MDQ6VXNlcjM0Njk5MzI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3469932?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/shaie",
            "html_url": "https://github.com/shaie",
            "followers_url": "https://api.github.com/users/shaie/followers",
            "following_url": "https://api.github.com/users/shaie/following{/other_user}",
            "gists_url": "https://api.github.com/users/shaie/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/shaie/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/shaie/subscriptions",
            "organizations_url": "https://api.github.com/users/shaie/orgs",
            "repos_url": "https://api.github.com/users/shaie/repos",
            "events_url": "https://api.github.com/users/shaie/events{/privacy}",
            "received_events_url": "https://api.github.com/users/shaie/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2020-10-18T09:13:44Z",
        "updated_at": "2020-10-20T11:50:48Z",
        "closed_at": "2020-10-20T11:50:48Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/huggingface/transformers/pulls/7880",
            "html_url": "https://github.com/huggingface/transformers/pull/7880",
            "diff_url": "https://github.com/huggingface/transformers/pull/7880.diff",
            "patch_url": "https://github.com/huggingface/transformers/pull/7880.patch"
        },
        "body": "I'm using transformers 3.3.1 and run a training script with `--save_total_limit 3`. I hit the exception below, and after debugging the code found that it wrongly tries to index into the `best_model_checkpoint`'s *str* rather than the `sorted_checkpoints` array. When running without the fix I got this exception:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/<HOME>/.conda/envs/transformers/lib/python3.7/site-packages/transformers/trainer.py\", line 921, in _save_training\r\n    self._rotate_checkpoints(use_mtime=True)\r\n  File \"/<HOME>/.conda/envs/transformers/lib/python3.7/site-packages/transformers/trainer.py\", line 1283, in _rotate_checkpoints\r\n    checkpoints_sorted = self._sorted_checkpoints(use_mtime=use_mtime)\r\n  File \"/<HOME>/.conda/envs/transformers/lib/python3.7/site-packages/transformers/trainer.py\", line 1274, in _sorted_checkpoints\r\n    checkpoints_sorted[best_model_index],\r\nTypeError: 'str' object does not support item assignment\r\n```\r\n\r\n# What does this PR do?\r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\nFixes # (issue)\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dimiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/master/CONTRIBUTING.md#start-contributing-pull-requests), \r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to the it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/master/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/master/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests? \r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors which may be interested in your PR.\r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\n albert, bert, XLM: @LysandreJik \r\n GPT2: @LysandreJik, @patrickvonplaten\r\n tokenizers: @mfuntowicz\r\n Trainer: @sgugger\r\n Benchmarks: @patrickvonplaten\r\n Model Cards: @julien-c\r\n Translation: @sshleifer\r\n Summarization: @sshleifer\r\n examples/distillation: @VictorSanh\r\n nlp datasets: [different repo](https://github.com/huggingface/nlp)\r\n rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n Text Generation: @patrickvonplaten, @TevenLeScao\r\n Blenderbot, Bart, Marian, Pegasus: @sshleifer\r\n T5: @patrickvonplaten\r\n Rag: @patrickvonplaten, @lhoestq\r\n EncoderDecoder: @patrickvonplaten\r\n Longformer, Reformer: @patrickvonplaten\r\n TransfoXL, XLNet: @TevenLeScao, @patrickvonplaten\r\n examples/seq2seq: @sshleifer\r\n examples/bert-loses-patience: @JetRunner\r\n tensorflow: @jplu\r\n examples/token-classification: @stefan-it\r\n documentation: @sgugger\r\n -->\r\n",
        "performed_via_github_app": null,
        "score": 1.0
    },
    {
        "url": "https://api.github.com/repos/huggingface/transformers/issues/6307",
        "repository_url": "https://api.github.com/repos/huggingface/transformers",
        "labels_url": "https://api.github.com/repos/huggingface/transformers/issues/6307/labels{/name}",
        "comments_url": "https://api.github.com/repos/huggingface/transformers/issues/6307/comments",
        "events_url": "https://api.github.com/repos/huggingface/transformers/issues/6307/events",
        "html_url": "https://github.com/huggingface/transformers/pull/6307",
        "id": 674625886,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NDY0Mjg0NTc1",
        "number": 6307,
        "title": "fix the shuffle agrument usage and the default",
        "user": {
            "login": "stas00",
            "id": 10676103,
            "node_id": "MDQ6VXNlcjEwNjc2MTAz",
            "avatar_url": "https://avatars.githubusercontent.com/u/10676103?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stas00",
            "html_url": "https://github.com/stas00",
            "followers_url": "https://api.github.com/users/stas00/followers",
            "following_url": "https://api.github.com/users/stas00/following{/other_user}",
            "gists_url": "https://api.github.com/users/stas00/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stas00/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stas00/subscriptions",
            "organizations_url": "https://api.github.com/users/stas00/orgs",
            "repos_url": "https://api.github.com/users/stas00/repos",
            "events_url": "https://api.github.com/users/stas00/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stas00/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2020-08-06T22:01:08Z",
        "updated_at": "2020-08-07T01:15:29Z",
        "closed_at": "2020-08-07T00:32:28Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/huggingface/transformers/pulls/6307",
            "html_url": "https://github.com/huggingface/transformers/pull/6307",
            "diff_url": "https://github.com/huggingface/transformers/pull/6307.diff",
            "patch_url": "https://github.com/huggingface/transformers/pull/6307.patch"
        },
        "body": "This is a follow up to the recently merged PR to https://github.com/huggingface/transformers/pull/6027\r\n\r\nThe `shuffle` wasn't handled correctly:\r\n\r\n```\r\ncd examples/text-classification\r\n./run_pl.sh\r\n```\r\n```\r\nTypeError: get_dataloader() missing 1 required positional argument: 'shuffle'\r\n```\r\nthis fixes it",
        "performed_via_github_app": null,
        "score": 1.0
    },
    {
        "url": "https://api.github.com/repos/huggingface/transformers/issues/5326",
        "repository_url": "https://api.github.com/repos/huggingface/transformers",
        "labels_url": "https://api.github.com/repos/huggingface/transformers/issues/5326/labels{/name}",
        "comments_url": "https://api.github.com/repos/huggingface/transformers/issues/5326/comments",
        "events_url": "https://api.github.com/repos/huggingface/transformers/issues/5326/events",
        "html_url": "https://github.com/huggingface/transformers/pull/5326",
        "id": 646553389,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NDQwODIwMTQ3",
        "number": 5326,
        "title": "In the run_ner.py example, give the optional label arg a default value",
        "user": {
            "login": "xuhdev",
            "id": 325476,
            "node_id": "MDQ6VXNlcjMyNTQ3Ng==",
            "avatar_url": "https://avatars.githubusercontent.com/u/325476?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xuhdev",
            "html_url": "https://github.com/xuhdev",
            "followers_url": "https://api.github.com/users/xuhdev/followers",
            "following_url": "https://api.github.com/users/xuhdev/following{/other_user}",
            "gists_url": "https://api.github.com/users/xuhdev/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xuhdev/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xuhdev/subscriptions",
            "organizations_url": "https://api.github.com/users/xuhdev/orgs",
            "repos_url": "https://api.github.com/users/xuhdev/repos",
            "events_url": "https://api.github.com/users/xuhdev/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xuhdev/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2020-06-26T23:07:14Z",
        "updated_at": "2020-07-01T00:39:33Z",
        "closed_at": "2020-06-30T23:45:36Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/huggingface/transformers/pulls/5326",
            "html_url": "https://github.com/huggingface/transformers/pull/5326",
            "diff_url": "https://github.com/huggingface/transformers/pull/5326.diff",
            "patch_url": "https://github.com/huggingface/transformers/pull/5326.patch"
        },
        "body": "Otherwise, if label is not specified, the following error occurs:\r\n\r\n\tTraceback (most recent call last):\r\n\t  File \"run_ner.py\", line 303, in <module>\r\n\t    main()\r\n\t  File \"run_ner.py\", line 101, in main\r\n\t    model_args, data_args, training_args = parser.parse_json_file(json_file=os.path.abspath(sys.argv[1]))\r\n\t  File \"/home/user/anaconda3/envs/bert/lib/python3.7/site-packages/transformers/hf_argparser.py\", line 159, in parse_json_file\r\n\t    obj = dtype(**inputs)\r\n\tTypeError: __init__() missing 1 required positional argument: 'labels'",
        "performed_via_github_app": null,
        "score": 1.0
    },
    {
        "url": "https://api.github.com/repos/huggingface/transformers/issues/3743",
        "repository_url": "https://api.github.com/repos/huggingface/transformers",
        "labels_url": "https://api.github.com/repos/huggingface/transformers/issues/3743/labels{/name}",
        "comments_url": "https://api.github.com/repos/huggingface/transformers/issues/3743/comments",
        "events_url": "https://api.github.com/repos/huggingface/transformers/issues/3743/events",
        "html_url": "https://github.com/huggingface/transformers/pull/3743",
        "id": 598066734,
        "node_id": "MDExOlB1bGxSZXF1ZXN0NDAyMDQ3MDAy",
        "number": 3743,
        "title": "JIT not compatible with PyTorch/XLA",
        "user": {
            "login": "LysandreJik",
            "id": 30755778,
            "node_id": "MDQ6VXNlcjMwNzU1Nzc4",
            "avatar_url": "https://avatars.githubusercontent.com/u/30755778?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/LysandreJik",
            "html_url": "https://github.com/LysandreJik",
            "followers_url": "https://api.github.com/users/LysandreJik/followers",
            "following_url": "https://api.github.com/users/LysandreJik/following{/other_user}",
            "gists_url": "https://api.github.com/users/LysandreJik/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/LysandreJik/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/LysandreJik/subscriptions",
            "organizations_url": "https://api.github.com/users/LysandreJik/orgs",
            "repos_url": "https://api.github.com/users/LysandreJik/repos",
            "events_url": "https://api.github.com/users/LysandreJik/events{/privacy}",
            "received_events_url": "https://api.github.com/users/LysandreJik/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2020-04-10T19:59:48Z",
        "updated_at": "2020-04-16T15:19:26Z",
        "closed_at": "2020-04-16T15:19:25Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/huggingface/transformers/pulls/3743",
            "html_url": "https://github.com/huggingface/transformers/pull/3743",
            "diff_url": "https://github.com/huggingface/transformers/pull/3743.diff",
            "patch_url": "https://github.com/huggingface/transformers/pull/3743.patch"
        },
        "body": "Tracing with JIT is not supported by TPUs. If `torch_xla` is detected in the environment, the `gelu_new` method won't be traced.\r\n\r\nIf tracing is done, the line:\r\n\r\n```py\r\nmodel = xm.send_cpu_data_to_device(model, xm.xla_device())\r\n```\r\nin `modeling_utils.py`\r\n\r\nwill raise:\r\n\r\n```py\r\nTypeError: can't pickle torch._C.ScriptFunction objects\r\n```\r\n\r\n\r\nthe `# noqa F401` is necessary, otherwise, flake8 gives the following error:\r\n```\r\nsrc/transformers/activations.py:37:9: F401 'torch_xla' imported but unused\r\n```",
        "performed_via_github_app": null,
        "score": 1.0
    },
    {
        "url": "https://api.github.com/repos/huggingface/transformers/issues/1668",
        "repository_url": "https://api.github.com/repos/huggingface/transformers",
        "labels_url": "https://api.github.com/repos/huggingface/transformers/issues/1668/labels{/name}",
        "comments_url": "https://api.github.com/repos/huggingface/transformers/issues/1668/comments",
        "events_url": "https://api.github.com/repos/huggingface/transformers/issues/1668/events",
        "html_url": "https://github.com/huggingface/transformers/pull/1668",
        "id": 514336719,
        "node_id": "MDExOlB1bGxSZXF1ZXN0MzMzOTcyNjM5",
        "number": 1668,
        "title": "Fixed training for TF XLM",
        "user": {
            "login": "tlkh",
            "id": 5409617,
            "node_id": "MDQ6VXNlcjU0MDk2MTc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5409617?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tlkh",
            "html_url": "https://github.com/tlkh",
            "followers_url": "https://api.github.com/users/tlkh/followers",
            "following_url": "https://api.github.com/users/tlkh/following{/other_user}",
            "gists_url": "https://api.github.com/users/tlkh/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tlkh/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tlkh/subscriptions",
            "organizations_url": "https://api.github.com/users/tlkh/orgs",
            "repos_url": "https://api.github.com/users/tlkh/repos",
            "events_url": "https://api.github.com/users/tlkh/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tlkh/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2019-10-30T01:35:20Z",
        "updated_at": "2019-10-30T16:08:01Z",
        "closed_at": "2019-10-30T16:08:00Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/huggingface/transformers/pulls/1668",
            "html_url": "https://github.com/huggingface/transformers/pull/1668",
            "diff_url": "https://github.com/huggingface/transformers/pull/1668.diff",
            "patch_url": "https://github.com/huggingface/transformers/pull/1668.patch"
        },
        "body": "This PR fixes `model.fit()` training for TF XLM model, and tested in a script similar to `run_tf_glue.py`. It also is tested and works with AMP and tf.distribute for mixed precision and multi-GPU training.\r\n\r\nThis changes some Python `assert` statements to `tf.debugging.assert_equal` both in `TFXLMMainLayer.call()` and `gen_mask()`\r\n\r\nOtherwise, errors encountered:\r\n* `TypeError: You are attempting to use Python control flow in a layer that was not declared to be dynamic. Pass 'dynamic=True' to the class constructor.`\r\n* `OperatorNotAllowedInGraphError: using a 'tf.Tensor' as a Python 'bool' is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.`",
        "performed_via_github_app": null,
        "score": 1.0
    },
    {
        "url": "https://api.github.com/repos/huggingface/transformers/issues/1418",
        "repository_url": "https://api.github.com/repos/huggingface/transformers",
        "labels_url": "https://api.github.com/repos/huggingface/transformers/issues/1418/labels{/name}",
        "comments_url": "https://api.github.com/repos/huggingface/transformers/issues/1418/comments",
        "events_url": "https://api.github.com/repos/huggingface/transformers/issues/1418/events",
        "html_url": "https://github.com/huggingface/transformers/pull/1418",
        "id": 502170195,
        "node_id": "MDExOlB1bGxSZXF1ZXN0MzI0MzAzMDIw",
        "number": 1418,
        "title": "DistillBert Documentation Code Example fixes",
        "user": {
            "login": "drc10723",
            "id": 8362865,
            "node_id": "MDQ6VXNlcjgzNjI4NjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8362865?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/drc10723",
            "html_url": "https://github.com/drc10723",
            "followers_url": "https://api.github.com/users/drc10723/followers",
            "following_url": "https://api.github.com/users/drc10723/following{/other_user}",
            "gists_url": "https://api.github.com/users/drc10723/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/drc10723/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/drc10723/subscriptions",
            "organizations_url": "https://api.github.com/users/drc10723/orgs",
            "repos_url": "https://api.github.com/users/drc10723/repos",
            "events_url": "https://api.github.com/users/drc10723/events{/privacy}",
            "received_events_url": "https://api.github.com/users/drc10723/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2019-10-03T16:30:20Z",
        "updated_at": "2019-10-03T19:51:34Z",
        "closed_at": "2019-10-03T19:51:34Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/huggingface/transformers/pulls/1418",
            "html_url": "https://github.com/huggingface/transformers/pull/1418",
            "diff_url": "https://github.com/huggingface/transformers/pull/1418.diff",
            "patch_url": "https://github.com/huggingface/transformers/pull/1418.patch"
        },
        "body": "Following code examples in the documentation are throwing errors:-\r\n\r\n1. [DistilBertForQuestionAnswering](https://huggingface.co/transformers/model_doc/distilbert.html#transformers.DistilBertForQuestionAnswering)\r\n\r\n```\r\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\r\nmodel = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased')\r\ninput_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\")).unsqueeze(0)  # Batch size 1\r\nstart_positions = torch.tensor([1])\r\nend_positions = torch.tensor([3])\r\noutputs = model(input_ids, start_positions=start_positions, end_positions=end_positions)\r\nloss, start_scores, end_scores = outputs[:2]\r\n```\r\n> ValueError: not enough values to unpack (expected 3, got 2)\r\n\r\n\r\n2. [TFDistilBertForMaskedLM](https://huggingface.co/transformers/model_doc/distilbert.html#transformers.TFDistilBertForMaskedLM)\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom transformers import DistilBertTokenizer, TFDistilBertForMaskedLM\r\n\r\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\r\nmodel = TFDistilBertForMaskedLM.from_pretrained('distilbert-base-uncased')\r\ninput_ids = tf.constant(tokenizer.encode(\"Hello, my dog is cute\"))[None, :]  # Batch size 1\r\noutputs = model(input_ids, masked_lm_labels=input_ids)\r\nprediction_scores = outputs[0]\r\n\r\n```\r\n> TypeError: call() got an unexpected keyword argument 'masked_lm_labels'\r\n\r\n3. [TFDistilBertForQuestionAnswering](https://huggingface.co/transformers/model_doc/distilbert.html#transformers.TFDistilBertForQuestionAnswering)\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom transformers import BertTokenizer, TFDistilBertForQuestionAnswering\r\n\r\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\r\nmodel = TFDistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased')\r\ninput_ids = tf.constant(tokenizer.encode(\"Hello, my dog is cute\"))[None, :]  # Batch size 1\r\nstart_positions = tf.constant([1])\r\nend_positions = tf.constant([3])\r\noutputs = model(input_ids, start_positions=start_positions, end_positions=end_positions)\r\nstart_scores, end_scores = outputs[:2]\r\n```\r\n> TypeError: call() got an unexpected keyword argument 'start_positions'\r\n\r\nThe first issue is just list indexing issue. Second and Third are due to implementation difference between Tensorflow and Pytorch DistillBERT. Tensorflow implementation doesn't have loss calculation inside `call`, but We do in `forward` for Pytorch.  I have updated code examples in the docstring.\r\n\r\nLet me know if you will be interested in a pull request for making same function API structure for Tensorflow implementation via adding loss calculation in `call function` similar to Pytorch.\r\n\r\nThis is my first issue. Let me know if you require any changes on pull request.\r\n\r\nRegards \ud83d\ude03 \r\nDharmendra ",
        "performed_via_github_app": null,
        "score": 1.0
    },
    {
        "url": "https://api.github.com/repos/huggingface/transformers/issues/1152",
        "repository_url": "https://api.github.com/repos/huggingface/transformers",
        "labels_url": "https://api.github.com/repos/huggingface/transformers/issues/1152/labels{/name}",
        "comments_url": "https://api.github.com/repos/huggingface/transformers/issues/1152/comments",
        "events_url": "https://api.github.com/repos/huggingface/transformers/issues/1152/events",
        "html_url": "https://github.com/huggingface/transformers/pull/1152",
        "id": 487169075,
        "node_id": "MDExOlB1bGxSZXF1ZXN0MzEyNDg4NTA0",
        "number": 1152,
        "title": "fix adding special tokens",
        "user": {
            "login": "epwalsh",
            "id": 8812459,
            "node_id": "MDQ6VXNlcjg4MTI0NTk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8812459?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/epwalsh",
            "html_url": "https://github.com/epwalsh",
            "followers_url": "https://api.github.com/users/epwalsh/followers",
            "following_url": "https://api.github.com/users/epwalsh/following{/other_user}",
            "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions",
            "organizations_url": "https://api.github.com/users/epwalsh/orgs",
            "repos_url": "https://api.github.com/users/epwalsh/repos",
            "events_url": "https://api.github.com/users/epwalsh/events{/privacy}",
            "received_events_url": "https://api.github.com/users/epwalsh/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2019-08-29T20:48:39Z",
        "updated_at": "2019-08-30T21:29:48Z",
        "closed_at": "2019-08-30T21:21:59Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/huggingface/transformers/pulls/1152",
            "html_url": "https://github.com/huggingface/transformers/pull/1152",
            "diff_url": "https://github.com/huggingface/transformers/pull/1152.diff",
            "patch_url": "https://github.com/huggingface/transformers/pull/1152.patch"
        },
        "body": "Currently there is a bug when adding `additional_special_tokens` in the form of a tuple, instead of a list. To reproduce:\r\n\r\n```python\r\nfrom pytorch_transformers import AutoTokenizer\r\ntokenizer = AutoTokenizer.from_pretrained(\"xlnet-base-cased\")\r\ntokenizer.add_special_tokens({\"additional_special_tokens\": (\"@a@\", \"@b@\")})\r\ntokenizer.all_special_tokens\r\n```\r\n\r\nResults in:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-4-81549ce398a5> in <module>()\r\n----> 1 tokenizer.all_special_tokens\r\n\r\n~/GitHub/pytorch-transformers/pytorch_transformers/tokenization_utils.py in\r\nall_special_tokens(self)\r\n    677         set_attr = self.special_tokens_map\r\n    678         for attr_value in set_attr.values():\r\n--> 679             all_toks = all_toks + (attr_value if isinstance(attr_val\r\nue, (list, tuple)) else [attr_value])\r\n    680         all_toks = list(set(all_toks))\r\n    681         return all_toks\r\n\r\nTypeError: can only concatenate list (not \"tuple\") to list\r\n```",
        "performed_via_github_app": null,
        "score": 1.0
    },
    {
        "url": "https://api.github.com/repos/huggingface/transformers/issues/1075",
        "repository_url": "https://api.github.com/repos/huggingface/transformers",
        "labels_url": "https://api.github.com/repos/huggingface/transformers/issues/1075/labels{/name}",
        "comments_url": "https://api.github.com/repos/huggingface/transformers/issues/1075/comments",
        "events_url": "https://api.github.com/repos/huggingface/transformers/issues/1075/events",
        "html_url": "https://github.com/huggingface/transformers/pull/1075",
        "id": 483683583,
        "node_id": "MDExOlB1bGxSZXF1ZXN0MzA5NzEzODE1",
        "number": 1075,
        "title": "reraise EnvironmentError in modeling_utils.py",
        "user": {
            "login": "abhishekraok",
            "id": 783844,
            "node_id": "MDQ6VXNlcjc4Mzg0NA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/783844?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/abhishekraok",
            "html_url": "https://github.com/abhishekraok",
            "followers_url": "https://api.github.com/users/abhishekraok/followers",
            "following_url": "https://api.github.com/users/abhishekraok/following{/other_user}",
            "gists_url": "https://api.github.com/users/abhishekraok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/abhishekraok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/abhishekraok/subscriptions",
            "organizations_url": "https://api.github.com/users/abhishekraok/orgs",
            "repos_url": "https://api.github.com/users/abhishekraok/repos",
            "events_url": "https://api.github.com/users/abhishekraok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/abhishekraok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 9,
        "created_at": "2019-08-21T22:35:14Z",
        "updated_at": "2019-08-23T16:47:47Z",
        "closed_at": "2019-08-23T10:42:40Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/huggingface/transformers/pulls/1075",
            "html_url": "https://github.com/huggingface/transformers/pull/1075",
            "diff_url": "https://github.com/huggingface/transformers/pull/1075.diff",
            "patch_url": "https://github.com/huggingface/transformers/pull/1075.patch"
        },
        "body": "When an EnvironmentError occurs in modeling_utils.py, currently the code returns None. This causes a TypeError saying None is not iterable in the statement\r\n\r\n            config, model_kwargs = cls.config_class.from_pretrained(\r\n                pretrained_model_name_or_path, *model_args,\r\n                cache_dir=cache_dir, return_unused_kwargs=True,\r\n                force_download=force_download,\r\n                **kwargs\r\n            )",
        "performed_via_github_app": null,
        "score": 1.0
    },
    {
        "url": "https://api.github.com/repos/huggingface/transformers/issues/242",
        "repository_url": "https://api.github.com/repos/huggingface/transformers",
        "labels_url": "https://api.github.com/repos/huggingface/transformers/issues/242/labels{/name}",
        "comments_url": "https://api.github.com/repos/huggingface/transformers/issues/242/comments",
        "events_url": "https://api.github.com/repos/huggingface/transformers/issues/242/events",
        "html_url": "https://github.com/huggingface/transformers/pull/242",
        "id": 404944006,
        "node_id": "MDExOlB1bGxSZXF1ZXN0MjQ5MDEyODU5",
        "number": 242,
        "title": "Fix argparse type error",
        "user": {
            "login": "ksurya",
            "id": 932927,
            "node_id": "MDQ6VXNlcjkzMjkyNw==",
            "avatar_url": "https://avatars.githubusercontent.com/u/932927?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ksurya",
            "html_url": "https://github.com/ksurya",
            "followers_url": "https://api.github.com/users/ksurya/followers",
            "following_url": "https://api.github.com/users/ksurya/following{/other_user}",
            "gists_url": "https://api.github.com/users/ksurya/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ksurya/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ksurya/subscriptions",
            "organizations_url": "https://api.github.com/users/ksurya/orgs",
            "repos_url": "https://api.github.com/users/ksurya/repos",
            "events_url": "https://api.github.com/users/ksurya/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ksurya/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2019-01-30T20:11:10Z",
        "updated_at": "2019-02-01T11:15:01Z",
        "closed_at": "2019-02-01T11:14:56Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/huggingface/transformers/pulls/242",
            "html_url": "https://github.com/huggingface/transformers/pull/242",
            "diff_url": "https://github.com/huggingface/transformers/pull/242.diff",
            "patch_url": "https://github.com/huggingface/transformers/pull/242.patch"
        },
        "body": "Resolved the following error on executing `run_squad2.py --help`\r\n\r\n```TypeError: %o format: an integer is required, not dict```",
        "performed_via_github_app": null,
        "score": 1.0
    }
]